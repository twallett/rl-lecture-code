## Folder Structure

```bash
.
├── 03-MAB
│   └── EpsilonGreedy
├── 04-DP
│   └── IterativePolicyEvaluation
├── 05-MC
│   ├── MonteCarloExploringStarts
│   └── MonteCarloPrediction
├── 06-TD
│   └── TDPrediction
├── 07-FA
│   └── Base
├── 08-DQN
│   └── Base
├── 09-PG
│   └── Base
├── 10-APG
│   └── Base
├── 11-MCTS
│   └── Base
├── .gitignore
├── LICENSE
└── README.md
```

## Environments 

```markdown
.
├── 03-MAB
│   └── EpsilonGreedy `Bernoulli & Gaussian generated environment using numpy`
├── 04-DP
│   └── IterativePolicyEvaluation `GridWorldEnv`
├── 05-MC
│   ├── MonteCarloExploringStarts `GridWorldEnv`
│   └── MonteCarloPrediction `GridWorldEnv`
├── 06-TD
│   └── TDPrediction `GridWorldEnv`
├── 07-FA
│   └── Base `MountainCarContinuous-v0`
├── 08-DQN
│   └── Base `CartPole-v1`
├── 09-PG
│   └── Base `CartPole-v1`
├── 10-APG
│   └── Base `CartPole-v1`
├── 11-MCTS
│   └── Base `CartPole-v1`
├── .gitignore
├── LICENSE
└── README.md
```

## <u> Reinforcement Learning Lecture Code </u>

DATS 6450 Reinforcement Learning @ GWU Lecture Code 

This repository contains implementations of various Reinforcement Learning algorithms and concepts, organized by lecture topics. Each subdirectory corresponds to a specific lecture and includes code examples, explanations, and relevant environments.

### MAB - Epsilon Greedy

<table>
  <tr>
    <td style="width: 50%;">
      <img src="01-Ticker/plots/GRU_SPY_forecast.png" width="100%">
    </td>
  </tr>
</table>

### DP - Iterative Policy Evaluation

<table>
  <tr>
    <td style="width: 50%;">
      <img src="01-Ticker/plots/GRU_SPY_forecast.png" width="100%">
    </td>
  </tr>
</table>

### MC - Monte Carlo Prediction

<table>
  <tr>
    <td style="width: 50%;">
      <img src="01-Ticker/plots/GRU_SPY_forecast.png" width="100%">
    </td>
  </tr>
</table>

### TD - Temporal Difference Prediction

<table>
  <tr>
    <td style="width: 50%;">
      <img src="01-Ticker/plots/GRU_SPY_forecast.png" width="100%">
    </td>
  </tr>
</table>

### FA - Function Approximation

<table>
  <tr>
    <td style="width: 50%;">
      <img src="01-Ticker/plots/GRU_SPY_forecast.png" width="100%">
    </td>
  </tr>
</table>

### DQN - Deep Q-Network

<table>
  <tr>
    <td style="width: 50%;">
      <img src="01-Ticker/plots/GRU_SPY_forecast.png" width="100%">
    </td>
  </tr>
</table>

### PG - Policy Gradient

<table>
  <tr>
    <td style="width: 50%;">
      <img src="01-Ticker/plots/GRU_SPY_forecast.png" width="100%">
    </td>
  </tr>
</table>

### APG - Advanced Policy Gradient

<table>
  <tr>
    <td style="width: 50%;">
      <img src="01-Ticker/plots/GRU_SPY_forecast.png" width="100%">
    </td>
  </tr>
</table>

### MCTS - Monte Carlo Tree Search (MCTS)

<table>
  <tr>
    <td style="width: 50%;">
      <img src="01-Ticker/plots/GRU_SPY_forecast.png" width="100%">
    </td>
  </tr>
</table>

## References

Tensorflow Python API documentation ([Web Link](https://www.tensorflow.org/api_docs/python/tf/all_symbols))

## Usage

Each subdirectory contains its own set of implementations and explanatory notes. To explore the implementations and learn more about each concept, navigate to the respective subdirectory's README.md file.

Feel free to explore, experiment, and contribute to this open source project.
